---
title: "Madrid housing"
author: "Annunziata Alvarez-cascos"
date: "Spring, 2023"
output:
  html_document:
    df_print: paged
  html_notebook: default
  pdf_document: default
always_allow_html: yes
variant: gfm
preserve_yaml: yes
leafletmap: yes
---

```{r global_options, include=T, echo = F}
knitr::opts_chunk$set(echo = T, warning=FALSE, message=FALSE)
```

```{r import libraries}
rm(list=ls()) 
library(leaflet)
library(tidyverse)
library(patchwork)
library(MASS)
library(caret)
library(stringi)
library(dplyr)
library(ggplot2)
library(rpart)
library(rpart.plot)
library(randomForest)
library(e1071)
library(stats)
library(factoextra)
library(car)
```

Load the datasets

```{r Load datasets}
data  = read.csv("houses_Madrid.csv")

subtitle_data = read.csv("subtitles.csv", sep = ";", header = F)
colnames(subtitle_data) = c("subtitle", "lat", "long")
subtitle_data = subtitle_data[-c(1,2),]
```

Cleaning the dataset

```{r data cleaning}
#We delete the empty variables in the dataset and overfitting variables
data$X = NULL
data$latitude = NULL
data$longitude = NULL
data$portal = NULL
data$door = NULL
data$rent_price = NULL
data$rent_price_by_area = NULL
data$is_rent_price_known = NULL
data$are_pets_allowed = NULL
data$is_furnished = NULL
data$is_kitchen_equipped = NULL
data$has_private_parking = NULL
data$has_public_parking = NULL
data$operation = NULL
data$raw_address = NULL
data$sq_mt_useful = NULL
data$is_exact_address_hidden = NULL
data$is_buy_price_known = NULL
data = subset(data, data$built_year <= 2022)


#If a value in one of this variables is empty we assume is False or give it a name and translate variables if needed
data$is_floor_under[data$is_floor_under == ""] = "False"
data$is_new_development[data$is_new_development == ""] = "False"
data$has_central_heating[data$has_central_heating == ""] = "False"
data$has_individual_heating[data$has_individual_heating == ""] = "False"
data$has_ac[data$has_ac == ""] = "False"
data$has_fitted_wardrobes[data$has_fitted_wardrobes == ""] = "False"
data$has_lift[data$has_lift == ""] = "False"
data$is_exterior[data$is_exterior == ""] = "False"
data$has_garden[data$has_garden == ""] = "False"
data$has_pool[data$has_pool == ""] = "False"
data$has_terrace[data$has_terrace == ""] = "False"
data$has_balcony[data$has_balcony == ""] = "False"
data$has_storage_room[data$has_storage_room == ""] = "False"
data$is_accessible[data$is_accessible == ""] = "False"
data$is_parking_included_in_price[data$is_parking_included_in_price == ""] = "False"
data$has_green_zones[data$has_green_zones == ""] = "False"
data$is_orientation_east[data$is_orientation_east == ""] = "False"
data$is_orientation_west[data$is_orientation_west == ""] = "False"
data$is_orientation_north[data$is_orientation_north == ""] = "False"
data$is_orientation_south[data$is_orientation_south == ""] = "False"
data$house_type_id[data$house_type_id == "HouseType 1: Pisos"] = "HouseType 1: Flat"
data$house_type_id[data$house_type_id == "HouseType 2: Casa o chalet"] = "HouseType 2: Detached house"
data$house_type_id[data$house_type_id == "HouseType 4: Dúplex"] = "HouseType 4: Duplex"
data$house_type_id[data$house_type_id == "HouseType 5: Áticos"] = "HouseType 5: Attics"
data$house_type_id[data$house_type_id == ""] = "HouseType 3: Studio"

#We convert needed variables to factor
data$subtitle = as.factor(data$subtitle)
data$is_floor_under = as.factor(data$is_floor_under)
data$house_type_id = as.factor(data$house_type_id)
data$is_renewal_needed = as.factor(data$is_renewal_needed)
data$is_new_development = as.factor(data$is_new_development) #as it only has one factor we have to delete it 

data$has_central_heating = as.factor(data$has_central_heating)
data$has_individual_heating = as.factor(data$has_individual_heating)
data$has_ac = as.factor(data$has_ac)
data$has_fitted_wardrobes = as.factor(data$has_fitted_wardrobes)
data$house_type_id = as.factor(data$house_type_id)
data$has_lift = as.factor(data$has_lift)
data$is_exterior = as.factor(data$is_exterior)
data$has_garden = as.factor(data$has_garden)
data$has_pool = as.factor(data$has_pool)
data$has_terrace = as.factor(data$has_terrace)
data$has_balcony = as.factor(data$has_balcony)
data$has_storage_room = as.factor(data$has_storage_room)
data$is_accessible = as.factor(data$is_accessible)
data$has_green_zones = as.factor(data$has_green_zones)
data$energy_certificate = as.factor(data$energy_certificate)
data$has_parking = as.factor(data$has_parking)
data$is_parking_included_in_price = as.factor(data$is_parking_included_in_price)
data$is_orientation_north = as.factor(data$is_orientation_north)
data$is_orientation_south = as.factor(data$is_orientation_south)
data$is_orientation_east = as.factor(data$is_orientation_east)
data$is_orientation_west = as.factor(data$is_orientation_west)

#Recreate some variables
data$subtitle = stri_sub(data$subtitle, 1 ,-9)

north = data$is_orientation_north == "True"
south = data$is_orientation_south == "True"
east = data$is_orientation_east == "True"
west = data$is_orientation_west == "True"
data$orientation[north] = "north"
data$orientation[south] = "south"
data$orientation[east] = "east"
data$orientation[west] = "west"

data$is_orientation_north = NULL
data$is_orientation_south = NULL
data$is_orientation_east = NULL
data$is_orientation_west = NULL

#shuffle rows and merge both datasets
data = merge(data, subtitle_data, by = "subtitle")
n = nrow(data)
shuffled_indices = sample(1:n)
data = data[shuffled_indices, ]
data$lat = as.numeric(sub(",", ".", data$lat, fixed = TRUE))
data$long = as.numeric(sub(",", ".", data$long, fixed = TRUE))
```

```{r summary of clean dataset}
names(data)
dim(data)
str(data)

```

Split into training and testing set for our future model

```{r train and test partition}
idx=createDataPartition(data$buy_price, p = 0.75, list = FALSE)  
training = data[idx,]
testing = data[-idx,]
nrow(training) #75%
nrow(testing) 
```


##EXPLORATORY ANALYSIS

Let's visualize on the map whether if the prices are well distributed in the training and testing sets.

```{r dist prices map}
leaflet() %>% 
  addProviderTiles(providers$CartoDB.Positron) %>%
  setView(lng=median(data$long), lat=median(data$lat), zoom = 11) %>%
  addCircles(data = training,
             lng = ~long, 
             lat = ~lat,
             color = "black")%>%
  addCircles(data = testing,
             lng = ~long, 
             lat = ~lat,
             color = "lightblue")

#grey circles mean we might have in that district both testing and training, as the localizations correspond to each district and not each porperty
```

```{r price dist}
training %>% ggplot(aes(x=buy_price)) + geom_density(fill="navyblue") + scale_x_log10()
#Prices seem to be symmetric but with high variability.
```

Let explore a bit more into detail our variables and how they affect the price

1.  Analysis of the distribution of the prices of the properties: exploring the average price tendency in the different districts in Madrid.

```{r dist prices, message=FALSE, warning=FALSE}
data_p = training %>% dplyr::select(subtitle, buy_price, lat, long) %>% group_by(subtitle,  lat, long) %>%summarise(mean_price = mean(buy_price))

ggplot(data_p, aes(x = subtitle, y = mean_price)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Average price distribution",
       x = "Districts",
       y = "Average price")

#As in the plot we cannot properly see the districts but an oversll distribution, let's see which are the 
most_expensive = data_p$subtitle[which.max(data_p$mean_price)]
paste(most_expensive,data_p$mean_price[which.max(data_p$mean_price)],sep = " -> ") #Recoletos -> 2049893.62€ €
cheapest = data_p$subtitle[which.min(data_p$mean_price)]
paste(cheapest,data_p$mean_price[which.min(data_p$mean_price)],sep = " -> ") #San Cristóbal -> 99511.58€


color_pal <- colorNumeric(palette = "RdYlBu", domain = data_p$mean_price, reverse=F)
map = leaflet(data_p) %>% 
  fitBounds(-3.8209,40.33711,-2.4932,43.0546)%>% 
  addProviderTiles(providers$CartoDB.Positron) %>%
  setView(lng=median(data_p$long), lat=median(data_p$lat), zoom = 11) %>%
  addCircles(lng = ~long, 
             lat = ~lat,
             radius = 10,
             color = ~color_pal(mean_price),
             fillColor = ~color_pal(mean_price),
             fillOpacity = 1,
             label = data_p$subtitle) 

map %>% addLegend(position="bottomleft", pal = color_pal, values = ~mean_price, bins=5)

#We can see how depending on the district the house is, the price can vary up to aproximately 1.950.382€
```

2.Analysis of the properties sizes tendency in the different districts in Madrid.

```{r size tendency, message=FALSE, warning=FALSE}
data_p = training %>% dplyr::select(subtitle, sq_mt_built, lat, long) %>% group_by(subtitle, lat, long) %>% summarise(mean_sq = mean(sq_mt_built))

ggplot(data_p, aes(x = subtitle, y = mean_sq)) +
  geom_point() +
  geom_smooth(method = "lm", se = FALSE) +
  labs(title = "Distribution of size per district",
       x = "Districts",
       y = "Average size")

paste(data_p$subtitle[which.max(data_p$mean_sq)] ,data_p$mean_sq[which.max(data_p$mean_sq)], sep = " -> ") #Aravaca -> 285.08
paste(data_p$subtitle[which.min(data_p$mean_sq)], data_p$mean_sq[which.min(data_p$mean_sq)], sep = " -> ") #San Cristóbal -> 67.38

color_pal <- colorNumeric(palette = "RdYlBu", domain = data_p$mean_sq, reverse=F)
map = leaflet(data_p) %>% 
  fitBounds(-3.8209,40.33711,-2.4932,43.0546)%>% 
  addProviderTiles(providers$CartoDB.Positron) %>%
  setView(lng=median(data_p$long), lat=median(data_p$lat), zoom = 11) %>%
addCircleMarkers(lng = ~long, 
             lat = ~lat,
             radius = as.integer(data_p$mean_sq)^(1/3),
             fillOpacity = 0.3,
             label = data_p$subtitle)

map



```

Is there any linear relation between the size and the price of the houses?

```{r prize vs size, warning=FALSE}

ggplot(training, aes(x=sq_mt_built, y=buy_price)) + xlab("size") +ylab("price") + 
  geom_point() + ggtitle("Price vs size of living area")
#Linear relation but non-constant variability

ggplot(training, aes(x = log(sq_mt_built), y = log(buy_price) )) + xlab("size") +ylab("price") + geom_point() + ggtitle("Price vs size of living area")
#Better linear relation and more constant variability
```

3.  Analysis of the antiquity of the properties in relation to the price.

```{r price vs antiquity}
ggplot(training, aes(x=built_year, y=buy_price)) + xlab("year built") + ylab("price") + 
  geom_point() + ggtitle("Price vs antiquity of the house")

#It doesn't have any linear relation nor constant variability
```

4.  Exploration of location of properties.

```{r location, message=FALSE}
data_num = training %>% dplyr::select(subtitle, lat, long) %>% group_by(subtitle, lat, long) %>% summarise(count = length(subtitle))

paste(data_num$subtitle[which.max(data_num$count)] , data_num$count[which.max(data_num$count)], sep = " -> ") #Moncloa -> 271
paste(data_num$subtitle[which.min(data_num$count)] , data_num$count[which.min(data_num$count)], sep = " -> ") #Campo de las Naciones-Corralejos -> 1

name = paste(data_num$subtitle, data_num$count, sep = " ")
leaflet(data_num) %>% 
  fitBounds(-3.8209,40.33711,-2.4932,43.0546)%>% 
  addProviderTiles(providers$CartoDB.Positron) %>%
  setView(lng=median(data_num$long), lat=median(data_num$lat), zoom = 11) %>%
  addMarkers(lng = ~long, 
             lat = ~lat, 
             label = ~name)%>%
  addLabelOnlyMarkers(
    lng = -3.7635, lat = 40.32718,
    label = "Number of properties per district",
    labelOptions = labelOptions(textsize = "20px",noHide = T, textOnly = T)) 
 

```

5.  Distribution of types of properties: in general, in the most expensive district and in the cheapest district.

```{r types of props}
table = table(training$house_type_id)
pie(table, labels = paste(names(table), "\n", table, sep=""), main="Pie Chart")

idx1 = training$subtitle == most_expensive
table = table(training$house_type_id[idx1])

pie(table, labels = paste(names(table), "\n", table, sep=""), main= paste("Pie Chart of", most_expensive, sep = " "))

idx2 = training$subtitle == cheapest
table = table(training$house_type_id[idx2])
pie(table, labels = paste(names(table), "\n", table, sep=""), main=paste("Pie Chart of" , cheapest, sep = " "))

```

6.  Analysis of the prices in relation with the factor variables

```{r factor vars analysis}
wrap_plots(ggplot(training, aes(x = buy_price, color = has_lift, bins = 40)) +
  geom_freqpoly(binwidth = 10000),
ggplot(training, aes(x = buy_price, color = is_renewal_needed, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = is_new_development, fill = is_new_development, bins = 40)) +
  geom_freqpoly(binwidth = 10000) , ncol = 1, nrow = 3)

wrap_plots(ggplot(training, aes(x = buy_price, color = has_central_heating, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = has_individual_heating, bins = 40)) +
 geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = has_ac, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,ncol = 1, nrow = 3)

wrap_plots(ggplot(training, aes(x = buy_price, color = has_fitted_wardrobes, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = is_exterior, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = has_garden, bins = 40)) +
  geom_freqpoly(binwidth = 10000),ncol = 1, nrow = 3)

wrap_plots(ggplot(training, aes(x = buy_price, color = has_pool, bins = 40)) +
 geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = has_terrace, bins = 40)) +
  geom_freqpoly(binwidth = 10000),
ggplot(training, aes(x = buy_price, color = has_balcony, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,ncol = 1, nrow = 3)

wrap_plots(ggplot(training, aes(x = buy_price, color = has_storage_room, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = is_accessible, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = has_green_zones, bins = 40)) +
  geom_freqpoly(binwidth = 10000),ncol = 1, nrow = 3)

wrap_plots(ggplot(training, aes(x = buy_price, color = energy_certificate, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = has_parking, bins = 40)) +
  geom_freqpoly(binwidth = 10000) ,
ggplot(training, aes(x = buy_price, color = is_parking_included_in_price, bins = 40)) +
  geom_freqpoly(binwidth = 10000), ncol = 1, nrow = 3)

#As we can see, these plots don't suggest any of these variables could be used for an accurate prediction of our target variable: buy_price

```

Does orientation have to do with high prices?

```{r orientation analysis}
ori = subset(training, !is.na(training$orientation))
ggplot(ori, aes(x = buy_price, col=orientation)) + geom_histogram(position = position_dodge()) 

#It doesn't seem so
```


Let's find high correlations between the predictors we analysed at the beginning to see if they could work.

```{r correlations}
training$n_rooms = as.numeric(training$n_rooms)
correlations <- cor(training[,c(4, 5, 6, 7, 8, 14, 15, 19, 38, 39 )])
corr_price <- sort(correlations["buy_price",], decreasing = T)
corr=data.frame(corr_price)
ggplot(corr,aes(x = row.names(corr), y = corr_price)) + 
  geom_bar(stat = "identity", fill = "brown") + 
  scale_x_discrete(limits= row.names(corr)) +
  labs(x = "Predictors", y = "Price", title = "Correlations") 
  
```

As we have seen the most relevant predictors are the number of rooms and the price of the area.

```{r}
#lf1 <- lm(buy_price~ sq_mt_built, data = training)
#summary(lf1)

#lf2 <- lm(buy_price~ sq_mt_allotment, data = training)
#summary(lf2)

lf3 <- lm(buy_price~ n_rooms, data = training)
summary(lf3)

lf8 <- lm(buy_price~ buy_price_by_area, data = training)
summary(lf8)

#lf4 <- lm(buy_price~ n_bathrooms, data = training)
#summary(lf4)

#lf5 <- lm(buy_price~ n_floors, data = training)
#summary(lf5)

#lf6 <- lm(buy_price~ lat, data = training)
#summary(lf6)

#lf7 <- lm(buy_price~ long, data = training)
#summary(lf7)

```

However, as with the number of rooms R2 is 38% and with the price per area is rougly 26% it means those variables in their own are not very significant.

```{r}
lf3 <- lm(log(buy_price)~ n_rooms, data = training)
summary(lf3) #R2 = 41.38%

lf8 <- lm(log(buy_price)~ buy_price_by_area, data = training)
summary(lf8) #R2 = 38.45%

lf8 <- lm(buy_price~ log(buy_price_by_area), data = training)
summary(lf8) #r2 = 21.57% too low
```

```{r}
linFit3 <- lm(log(buy_price)~ n_rooms, data = training)
summary(linFit3) #R2 = 41.38%

linFit8 <- lm(log(buy_price)~ log(buy_price_by_area), data = training)
summary(linFit8) #R2 = 42.22%

```

As we have seen with applying a logaritmic regression in *buy_price* we would get a higher significancy for the number of rooms (aprox. 41%) and with the logarithm of the price by area (aprox. 42%) but would be still a little bit weak.

As the significance of the predictors by their own doesn't give us a high proportion of variance, we are going to study how would multiple regression with different predictors work.

```{r}
#Firstly, we start by trying with the most relevant predictors seen in the barplot. 
mr1 <- lm(log(buy_price) ~ n_rooms + log(buy_price_by_area) , data=training)
summary(mr1) #R2 = 79.78%

#Then we start adding different predictors in different ways to see how they respond
mr2 <- lm(log(buy_price) ~ n_rooms + log(buy_price_by_area) + lat + long, data=training)
summary(mr2) #R2 = 79.89%

mr3 <- lm(log(buy_price) ~ n_rooms + log(sq_mt_built) + lat*long, data=training)
summary(mr3) #R2 = 80.22%

mr4 <- lm(log(buy_price) ~ n_rooms + n_bathrooms + log(sq_mt_built) + lat*long, data=training)
summary(mr4) #R2 = 80.67%

mr5 <- lm(log(buy_price) ~ n_rooms + n_bathrooms + n_floors + log(sq_mt_built) + lat*long, data=training)
summary(mr5) #n_floors diminishes our R2 (R2 = 64.44%)

mr6 <- lm(log(buy_price) ~ n_rooms + n_bathrooms + log(sq_mt_allotment) + lat*long, data=training)
summary(mr6) #sq_mt_allotment gives us a very low R2 (R2 = 42.24%)


mr7 <- lm(log(buy_price) ~ n_rooms + n_bathrooms + log(sq_mt_built) + log(buy_price_by_area) + lat*long, data=training)
summary(mr7) #R2 = 1, which indicates a perfect fit for our model

```

After the exploratory analysis of our dataset and its variables, we are happy to say we have now have the predictors we will use to fit for our models.

As the R2 was too accurate, I decided to perform a K-fold Cross-Validation to check whether the model was overfitting to the training data or not.

```{r}
#Create new dataset we the variables we are going to use selected before. 
new_training = training%>% dplyr::select(n_rooms, n_bathrooms, sq_mt_built, buy_price_by_area, buy_price, lat, long)
new_training = na.omit(new_training)
new_testing = testing%>% dplyr::select(n_rooms, n_bathrooms, sq_mt_built, buy_price_by_area, buy_price, lat, long)
new_testing = na.omit(new_testing)

model <-  lm(log(buy_price) ~ n_rooms + n_bathrooms + log(sq_mt_built) + log(buy_price_by_area), data=new_training)
summary(model)
predicted <- predict(model, newdata = new_testing)
error <- sqrt(mean((new_testing$buy_price - predicted)^2))

# Check for overfitting
train_predicted <- predict(model, newdata = new_training)
train_error <- sqrt(mean((new_training$buy_price - train_predicted)^2))

if (error > train_error) {
  message("The model is overfitting to the training data.")
} else {
  message("The model is not overfitting to the training data.")
}

summary(model)$adj.r.squared

library(car)
vif(model) 
```

As we can see,the model is not overfitting to the training data but we have multicollinearity regarding the latitude and longitude as they should be treated as categorical variables. 



Now we are going to use some regression techniques to select the optimal model.

##MODEL SELECTION
```{r data cleaning formodel selection}
colSums(is.na(training))
colSums(is.na(testing))
training$is_new_development = NULL
training$orientation = as.factor(training$orientation)
training$neighborhood_id = as.factor(training$neighborhood_id)
testing$is_new_development = NULL
testing$orientation = as.factor(testing$orientation)
testing$neighborhood_id = as.factor(testing$neighborhood_id)
training  = subset(training, select = -c(n_floors, sq_mt_allotment,parking_price, id , title , street_name, street_number, lat, long ))
testing  = subset(testing, select = -c(n_floors, sq_mt_allotment,parking_price, id , title , street_name, street_number, lat, long ))

training$neighborhood_id = factor(training$neighborhood_id, levels = unique(training$neighborhood_id))
testing$neighborhood_id = factor(testing$neighborhood_id, levels = unique(training$neighborhood_id))

training$floor <- factor(training$floor, levels = unique(training$floor))
testing$floor <- factor(testing$floor, levels = unique(training$floor))

training$subtitle <- factor(training$subtitle, levels = unique(training$subtitle))
testing$subtitle <- factor(testing$subtitle, levels = unique(training$subtitle))

training = na.omit(training)
testing = na.omit(testing)
```

```{r stepwise regression}
library(car)
library(caret)
modelo = lm(buy_price ~. , data = training)
#vif(modelo) #there are aliased coefficients in the model

#Lets choose the best model using stepwise regression so that we can get rid of multicollinearity
mod_back = step(modelo, direction = "backward")
summary(mod_back)
final_mod_back = mod_back$finalModel
vif(mod_back)
mod_forw = step(modelo, direction = "forward")
summary(mod_forw)
final_mod_forw = mod_forw$finalModel
#vif(mod_forw)
mod_both = step(modelo, direction = "both")
summary(mod_both)
final_mod_both = mod_both$finalModel
vif(mod_both)


tab <- matrix(c(AIC(mod_back), AIC(mod_forw), AIC(mod_both), BIC(mod_back), BIC(mod_forw), BIC(mod_both)), ncol=3, byrow=TRUE)
colnames(tab) <- c('backward','forward','hybrid')
rownames(tab) <- c('AIC','BIC')
as.table(tab)

#calculate min value
min_val = min(c(AIC(mod_back), AIC(mod_forw), AIC(mod_both), BIC(mod_forw), BIC(mod_back), BIC(mod_both)))
min_val

summary(mod_both)$adj.r.squared

par(mfrow = c(2, 2))
plot(mod_both)

```

THE LASSO

```{r The Lasso}
library(glmnet)

new_data = rbind(training, testing)
new_data$buy_price_by_area = NULL #nuevo
x = model.matrix(buy_price ~ ., new_data)[,-new_data$buy_price]
y = new_data$buy_price

lasso.fit = cv.glmnet(x, y, alpha = 1)

plot(lasso.fit)
lasso.fit

opt.lambda = lasso.fit$lambda.min

ctrl = trainControl(method = "cv", number = 5, verboseIter = TRUE)

lasso = train(buy_price ~ ., data = training, method = "glmnet", trControl = ctrl, tuneGrid = expand.grid(alpha = 1, lambda = opt.lambda ))

y.pred = predict(lasso, newdata = testing)

accuracy = cor(y.pred, testing$buy_price) ** 2
accuracy #91.23%

lasso_model = glmnet(x, y, alpha = 1, lambda = opt.lambda)
#coef(best_model)

plot(lasso.fit$glmnet.fit, 
     "lambda", label=FALSE)
```

RIDGE REGRESSION
```{r Ridge Regression}
x = model.matrix(buy_price ~., new_data)[,-new_data$buy_price]
y = new_data$buy_price

ridge.fit = cv.glmnet(x, y, alpha = 0)

plot(ridge.fit)
ridge.fit

opt.lambda = ridge.fit$lambda.min

ctrl = trainControl(method = "cv", number = 5, verboseIter = TRUE)

ridge = train(buy_price ~ ., data = training, method = "glmnet", trControl = ctrl, tuneGrid = expand.grid(alpha = 0, lambda =opt.lambda ))

y.pred = predict(ridge, newdata = testing)

accuracy = cor(y.pred, testing$buy_price) ** 2
accuracy #89.24%

ridge_model = glmnet(x, y, alpha = 0, lambda = opt.lambda)
#coef(best_model)

plot(ridge.fit$glmnet.fit, 
     "lambda", label=FALSE)
```

ELASTIC NET
```{r Elastic Net}
library(glmnet)
training$buy_price_by_area = NULL #nuevo
testing$buy_price_by_area = NULL #nuevo
x = model.matrix(buy_price ~ ., training)[,-training$buy_price]
y = training$buy_price
set.seed(123)
model = train(
  buy_price ~., data = training, method = "glmnet",
  trControl = trainControl("cv", number = 10),
  tuneLength = 10)
model$bestTune

en.fit = cv.glmnet(x, y, alpha = model$bestTune$alpha)

plot(en.fit)
en.fit

plot(en.fit$glmnet.fit, 
     "lambda", label=FALSE)

opt.lambda = en.fit$lambda.min


ctrl = trainControl(method = "cv", number = 5, verboseIter = TRUE)

elasticnet = train(buy_price ~ ., data = training, method = "glmnet", trControl = ctrl, tuneGrid = expand.grid(alpha = model$bestTune$alpha, lambda =opt.lambda ))

y.pred = predict(elasticnet, newdata = testing)


# Calculate R-squared
rsq <- cor(y.pred, testing$buy_price)^2
rsq

elasticnet_model = glmnet(x, y, alpha = model$bestTune$alpha, lambda = opt.lambda)
enet_coefs = coef(elasticnet_model)
```
####NOW MACHINE LEARNING

```{r random forest total}

#Random Forest
library(randomForest)

#param_grid <-expand.grid(mtry = c(2, 4, 6), ntree = seq(200, 700, 50))
param_grid <-expand.grid(mtry = c(2, 4, 6))
ctrl <- trainControl(method = "cv", number = 10, savePredictions = TRUE)

training2 = training[,-c(1,7)]
testing2 = testing[,-c(1,7)]
rf <- train(buy_price ~ ., data = training2, method = "rf",
                  tuneGrid = param_grid, trControl = ctrl)


rf$bestTune
#rf_model <- randomForest(buy_price ~ ., data = training, mtry = rf$bestTune$mtry, importance = TRUE)
#Error in randomForest.default(m, y, ...) : 
#Can not handle categorical predictors with more than 53 categories


rf_model <- randomForest(buy_price ~ ., data = training2, mtry = rf$bestTune$mtry, importance = TRUE)

pred <- predict(rf_model, newdata = testing2)
accuracy <- 1 - mean(abs(pred - testing2$buy_price))/mean(testing2$buy_price) #there is a na in pred
accuracy
#89.92%
varImpPlot(rf_model)
```

```{r big PCA}
library(stats)
library(factoextra)
set = training

set$n_rooms = as.numeric(set$n_rooms)
set$buy_price = as.numeric(set$buy_price)
set$buy_price_by_area = as.numeric(set$buy_price_by_area)

set$floor = as.numeric(set$floor)
set$neighborhood_id = as.numeric(set$neighborhood_id)
set$is_floor_under = as.numeric(set$is_floor_under)
set$is_renewal_needed = as.numeric(set$is_renewal_needed)
set$has_central_heating = as.numeric(set$has_central_heating)
set$has_individual_heating = as.numeric(set$has_individual_heating)
set$has_ac = as.numeric(set$has_ac)
set$has_fitted_wardrobes = as.numeric(set$has_fitted_wardrobes)
set$has_lift = as.numeric(set$has_lift)
set$is_exterior = as.numeric(set$is_exterior)
set$has_garden = as.numeric(set$has_garden)
set$has_pool = as.numeric(set$has_pool)
set$has_terrace = as.numeric(set$has_terrace)
set$has_balcony = as.numeric(set$has_balcony)
set$has_storage_room = as.numeric(set$has_storage_room)
set$is_accessible = as.numeric(set$is_accessible)
set$has_green_zones = as.numeric(set$has_green_zones)
set$energy_certificate = as.numeric(set$energy_certificate)
set$has_parking = as.numeric(set$has_parking)
set$orientation = as.numeric(set$orientation)
set$house_type_id = as.numeric(set$house_type_id)


df_mean <- aggregate(set[, c('sq_mt_built', 'n_rooms', 'n_bathrooms', 'buy_price', 'buy_price_by_area', 'floor', 'neighborhood_id', 'is_floor_under', 'house_type_id', 'is_renewal_needed',
                                  'has_central_heating','has_individual_heating', 'has_ac', 'has_fitted_wardrobes', 'has_lift',
                                  'is_exterior', 'has_garden', 'has_pool', 'has_terrace','has_balcony', 'has_storage_room', 'is_accessible',
                                  'has_green_zones', 'energy_certificate', 'has_parking', 'orientation')], 
                     by = list(district = set$subtitle), FUN = mean)
df_mean

# Select the variables to use for clustering and dimensionality reduction
X <- df_mean[, c('sq_mt_built', 'n_rooms', 'n_bathrooms', 'buy_price', 'buy_price_by_area', 'floor', 'neighborhood_id', 'is_floor_under', 'house_type_id', 'is_renewal_needed',
                 'has_central_heating','has_individual_heating', 'has_ac', 'has_fitted_wardrobes',
                 'is_exterior', 'has_garden', 'has_pool', 'has_terrace','has_balcony', 'has_storage_room', 'is_accessible',
                 'has_green_zones', 'energy_certificate', 'has_parking', 'orientation')]

# Scale the data using scale()
X_scaled <- scale(X)

# Apply K-means clustering with 3 clusters
set.seed(10)
kmeans <- kmeans(X_scaled, centers = 3)

# Plot the results using fviz_cluster()
fviz_cluster(kmeans, data = X_scaled, geom = 'point', pointsize = 2) +
  labs(title = 'Cluster Assignments by District') +
  geom_text(aes(label = df_mean$district), size = 3, nudge_x = 0.5, nudge_y = 0.5)
groups = kmeans$cluster

# Crear un data frame con los nombres de los distritos y su grupo correspondiente
district_groups = data.frame(subtitle = df_mean$district, group = groups)

# Ordenar el data frame por grupo y distrito
district_groups = district_groups[order(district_groups$group, district_groups$subtitle), ]

# Imprimir los nombres de los distritos por grupo
for (i in unique(groups)) {
  g = list(district_groups[district_groups$group == i, ]$subtitle)
  cat("Group", i, ":\n")
  print(g)
  cat("\n")
}

# Apply PCA for dimensionality reduction
pca <- prcomp(X_scaled, scale = TRUE)

# Plot the results using fviz_pca_biplot()
fviz_pca_biplot(pca, col.var = 'contrib', gradient.cols = c('#FFEDA0', '#F03B20'))
pca
sort(pca$rotation[,1])

```

```{r big Kmeans}
training$n_rooms = as.numeric(training$n_rooms)
training$buy_price = as.numeric(training$buy_price)
training$buy_price_by_area = as.numeric(training$buy_price_by_area)
training = na.omit(training)
df_mean <- aggregate(training[, c('sq_mt_built', 'n_rooms',  'buy_price', 'buy_price_by_area', 'n_bathrooms')], 
                     by = list(district = training$subtitle), FUN = mean)
df_mean

# Select the variables to use for clustering and dimensionality reduction
X <- df_mean[, c('sq_mt_built', 'n_rooms',  'buy_price', 'buy_price_by_area', 'n_bathrooms')]

# Scale the data using scale()
X_scaled <- scale(X)

# Apply K-means clustering with 3 clusters
set.seed(10)

library(ggplot2)

# Calcula la suma de cuadrados dentro de los clusters para diferentes valores de k
suma_cuadrados <- c()
for (k in 1:10) {
  modelo <- kmeans(X, centers = k)
  suma_cuadrados[k] <- modelo$tot.withinss
}

# Grafica la suma de cuadrados en función del número de clusters
datos_codo <- data.frame(k = 1:10, suma_cuadrados = suma_cuadrados)
ggplot(datos_codo, aes(x = k, y = suma_cuadrados)) +
  geom_line() +
  geom_point() 
    

kmeans <- kmeans(X_scaled, centers = 3)

# Plot the results using fviz_cluster()
fviz_cluster(kmeans, data = X_scaled, geom = 'point', pointsize = 2) +
  labs(title = 'Cluster Assignments by District') +
  geom_text(aes(label = df_mean$district), size = 3, nudge_x = 0.5, nudge_y = 0.5)
groups = kmeans$cluster

# Crear un data frame con los nombres de los distritos y su grupo correspondiente
district_groups = data.frame(subtitle = df_mean$district, group = groups)

# Ordenar el data frame por grupo y distrito
district_groups = district_groups[order(district_groups$group, district_groups$subtitle), ]

# Imprimir los nombres de los distritos por grupo
for (i in unique(groups)) {
  g = list(district_groups[district_groups$group == i, ]$subtitle)
  cat("Group", i, ":\n")
  print(g)
  cat("\n")
}
# Apply PCA for dimensionality reduction
pca <- prcomp(X_scaled, scale = TRUE)

# Plot the results using fviz_pca_biplot()
fviz_pca_biplot(pca, col.var = 'contrib', gradient.cols = c('#FFEDA0', '#F03B20'))
pca
sort(pca$rotation[,1])


df_mean$groups=district_groups$group[match(df_mean$district, district_groups$subtitle)]
obs1=subset(df_mean, groups == 1)
obs2=subset(df_mean, groups == 2)
obs3=subset(df_mean, groups == 3)
summary(obs1)
summary(obs2)
summary(obs3)


```

```{r subset}
training = training[, c('subtitle', 'sq_mt_built', 'n_rooms',  'buy_price', 'buy_price_by_area', 'n_bathrooms')]
testing = testing[, c('subtitle', 'sq_mt_built', 'n_rooms',  'buy_price', 'buy_price_by_area', 'n_bathrooms')]
```

```{r decision trees}
library(rpart)
library(rpart.plot)

#Regression tree

set.seed(123)
param_grid <-expand.grid(cp = seq(0.01, 0.5, 0.01))#, maxdepth = seq(2, 10, 1), 
   #                                     minsplit = seq(10, 100, 10), minbucket = seq(2, 20, 1))

#It doesn't work unless I get rid of the others hyperparams

#param_grid <-expand.grid(cp = seq(0.01, 0.5, 0.01))
ctrl <- trainControl(method = "cv", number = 10, savePredictions = TRUE)


reg_tree <- train(buy_price ~ ., data = training, method = "rpart",
                  tuneGrid = param_grid, trControl = ctrl)


reg_tree$bestTune
rt_model <- rpart(buy_price ~ ., data = training, method = "anova",
                     cp = reg_tree$bestTune$cp)
pred <- predict(rt_model, newdata = testing)
accuracy <- 1 - mean(abs(pred - testing$buy_price))/mean(testing$buy_price)
accuracy #76.62%

rpart.plot(rt_model)

```

```{r random forest}
#Random Forest
library(randomForest)

#param_grid <-expand.grid(mtry = c(2, 4, 6), ntree = seq(200, 700, 50))
param_grid <-expand.grid(mtry = seq(2, 4, 1))
ctrl <- trainControl(method = "cv", number = 10, savePredictions = TRUE)

training2 = training[,-1]
testing2 = testing[,-1]
rf <- train(buy_price ~ ., data = training2, method = "rf",
            tuneGrid = param_grid, trControl = ctrl)

rf$bestTune
#rf_model <- randomForest(buy_price ~ ., data = training, mtry = rf$bestTune$mtry, importance = TRUE)
#Error in randomForest.default(m, y, ...) : 
#Can not handle categorical predictors with more than 53 categories


rf_model <- randomForest(buy_price ~ ., data = training2, mtry = rf$bestTune$mtry, importance = TRUE)

pred <- predict(rf_model, newdata = testing2)
accuracy <- 1 - mean(abs(pred - testing2$buy_price))/mean(testing2$buy_price) #there is a na in pred
accuracy
plot(rf)
#98.25%
varImpPlot(rf_model)

tree <- getTree(rf_model, k=1)

# Plot the tree
plot(tree)

```

```{r SVM}

library(e1071)
param_grid = expand.grid(degree = seq(1,10,1), scale = 1, C = seq(0.5, 3, 0.5) )

ctrl <- trainControl(method = "cv", number = 10, savePredictions = TRUE)


svm <- train(buy_price ~ ., data = training, method = "svmPoly",
                  tuneGrid = param_grid, trControl = ctrl)

svm$bestTune
svm_model = svm(buy_price~., data = training, type = "C-classification", kernel = "polynomial",
          degree = svm$bestTune$degree)

pred <- predict(svm_model, newdata = testing)
accuracy <- 1 - mean(abs(pred - testing$buy_price))/mean(testing$buy_price)
accuracy
```

```{r Neural networks}
library(tidymodels)
library(skimr)
library(DataExplorer)
library(ggpubr)
library(mosaicData)
library(h2o)

#PREPROCESSING

transformer = recipe(
  formula = buy_price ~ .,
  data =  training) %>%
  step_naomit(all_predictors()) %>%
  step_nzv(all_predictors()) %>%
  step_center(all_numeric(), -all_outcomes()) %>%
  step_scale(all_numeric(), -all_outcomes()) %>%
  step_dummy(all_nominal(), -all_outcomes())

transformer

# Se entrena el objeto recipe
transformer_fit=prep(transformer)

# Se aplican las transformaciones al conjunto de entrenamiento y de test
training_prep = bake(transformer_fit, new_data = training)
testing_prep = bake(transformer_fit, new_data = testing)

glimpse(training_prep)


# Inicialización del cluster
# ==============================================================================
h2o.init(
  nthreads = -1,
  max_mem_size = "4g"
)


# Se eliminan los datos del cluster por si ya había sido iniciado.
h2o.removeAll()
h2o.no_progress()

#Se transfieren los datos al cluster de H2O
training  <- as.h2o(training_prep, key = "training")
testing   <- as.h2o(testing_prep, key = "testing")

# Espacio de búsqueda de cada hiperparámetro

hiperparameters <- list(
  epochs = c(50, 100, 500),
  hidden = list(5, 10, 25, 50, c(10, 10))
)


# Búsqueda por validación cruzada
ans <- 'buy_price'
pred <- setdiff(colnames(training), ans)

grid <- h2o.grid(
  algorithm    = "deeplearning",
  activation   = "Rectifier",
  x            = pred,
  y            = ans,
  training_frame  = training,
  nfolds       = 3, #validacion cruzada
  standardize  = FALSE,
  hyper_params = hiperparameters,
  search_criteria = list(strategy = "Cartesian"),
  seed         = 123,
  grid_id      = "grid"
)

# Resultados del grid
grid_results <- h2o.getGrid(
  sort_by = 'rmse',
  grid_id = "grid",
  decreasing = FALSE
)

data.frame(grid_results@summary_table)

# Mejor modelo encontrado
final_model <- h2o.getModel(grid_results@model_ids[[1]])
h2o.saveModel(model = final_model, path = "~/Desktop/CDS 492/CDS-492-aah/final_model")

preds <- h2o.predict(
  object  = final_model,
  newdata = testing
)

pred <- h2o.predict(final_model, newdata = testing)
accuracy <- 1 - mean(abs(pred - testing$buy_price))/mean(testing$buy_price) #there is a na in pred
accuracy #0.9342887

preds <- preds %>%
  as_tibble() %>%
  mutate(val = as.vector(testing$buy_price))

preds %>% head(10)

final_model@allparameters

```
Lets build an application with Elastic net model.
```{r App code}
library(shiny)
library(h2o)
ui <- fluidPage(
  titlePanel("House price prediction"),
  sidebarLayout(
    sidebarPanel(
      numericInput("sq_mt_built", "Introduce the square meters of the house you are looking for:", min =15, max = 999 , value = 100),
      numericInput("n_rooms", "Introduce the number of rooms:", value = 3, min = 0, max = 24),
      numericInput("n_bathrooms", "Introduce the number of bathrooms:", value = 2, min = 1, max = 14),
      selectInput("subtitle", "Introduce the district you want to live in:", choices = sort(unique(data$subtitle))),
      selectInput("neighborhood_id", "Introduce the neighborhood you want to live in:", choices = "Select a district first"),
      selectInput("house_type_id", "What kind of house would you like to live in?:", choices = unique(data$house_type_id)),
      conditionalPanel(
        condition = "input.house_type_id != 'HouseType 2: Detached house'",
        selectInput("floor", "Select floor number:", choices = c(sort(unique(data$floor))))),
      
      selectInput("is_floor_under", "Is floor under?:", choices=c("True", "False")),
      selectInput("is_renewal_needed", "Is renewal needed?:", choices=c("True", "False")),
      numericInput("built_year", "Year the house was built in:", value = 2022, min =1800),
      selectInput("has_central_heating", "Has central heating?:", choices=c("True", "False")),
      selectInput("has_individual_heating", "Has individual heating?:", choices=c("True", "False")),
      selectInput("has_ac", "Do you want to have AC?:", choices=c("True", "False")),
      selectInput("has_fitted_wardrobes", "Do you want to have fitted wardrobes?:", choices=c( "True", "False")),
      selectInput("has_lift", "Do you want to have a lift?:", choices=c("True", "False")),
      selectInput("is_exterior", "Do you want it to be exterior?:", choices=c("True", "False")),
      selectInput("has_garden", "Do you want to have a garden?:", choices=c( "True", "False")),
      selectInput("has_pool", "Do you want to have a pool?:", choices=c( "True", "False")),
      selectInput("has_terrace", "Do you want to have a terrace?:", choices=c( "True", "False")),
      selectInput("has_balcony", "Do you want to have a balcony?:", choices=c( "True", "False")),
      selectInput("has_storage_room", "Do you want to have a storage room?:", choices=c( "True", "False")),
      selectInput("is_accessible", "Do you want it to be accessible?:", choices=c( "True", "False")),
      selectInput("has_green_zones", "Do you want to have a green zones?:", choices=c( "True", "False")),
      selectInput("energy_certificate", "What energy certificate would you like it to have?:", choices= sort(unique(data$energy_certificate))),
      selectInput("orientation", "Any preference in orientation:", choices=c("east", "west", "south", "north")),
      
      selectInput("has_parking", "Do you want to have parking?:", choices=c( "True", "False")),
      conditionalPanel(
        condition = "input.has_parking == 'True'",
        selectInput("is_parking_included_in_price", "Parking included in price:", choices = c("True", "False"))),
      ),
      mainPanel(
      h3("The predicted price is:"),
      br(),
      textOutput("predicted_price"))
    )
  )



server = function(input, output, session) {
  
  
  h2o.init()
  model <- h2o.loadModel("final_model")
  
  get_neighborhoods=function(subtitle) {
    unique(data$neighborhood_id[data$subtitle == subtitle])
  }
  
  observe({
    subtitle = input$subtitle
    if (is.null(subtitle) || subtitle == "Select a district") {
      
      updateSelectInput(session, "neighborhood_id", choices = c("Select a district first"))
    } else {
      
      neighborhood_id = get_neighborhoods(subtitle)
      updateSelectInput(session, "neighborhood_id", choices = c( neighborhood_id))
    }
  })
  
  user_data = reactive({
    h2o.H2OFrame(sq_mt_built = input$sq_mt_built,
               n_rooms = input$n_rooms,
               n_bathrooms = input$n_bathrooms,
               subtitle = input$subtitle,
               floor = input$floor,
               is_floor_under = input$is_floor_under,
               neighborhood_id = input$neighborhood_id,
               house_type_id = input$house_type_id,
               is_renewal_needed = input$is_renewal_needed,
               has_central_heating = input$has_central_heating,
               has_individual_heating = input$has_individual_heating,
               built_year = input$built_year,
               has_ac = input$has_ac,
               has_fitted_wardrobes = input$has_fitted_wardrobes,
               has_lift = input$has_lift,
               has_pool = input$has_pool,
               has_storage_room = input$has_storage_room,
               energy_certificate = input$energy_certificate,
               orientation = input$orientation,
               is_exterior = input$is_exterior,
               has_terrace = input$has_terrace,
               is_accessible = input$is_accessible,
               has_parking = input$has_parking,
               has_garden = input$has_garden,
               has_balcony = input$has_balcony,
               has_green_zones = input$has_green_zones,
               is_parking_included_in_price = input$is_parking_included_in_price) })
    

    
  #predicted_price = reactive({ predict(elasticnet, user_data())})
  #predicted_price = reactive({ h2o.predict(final_model, user_data())})
  
  #output$predicted_price = renderText({predicted_price()})
  
   output$predicted_price <- renderText({
    user_data_frame <- as.data.frame(user_data())
    prediction <- as.numeric(h2o.predict(model, as.h2o(user_data_frame)))
    paste0("$", formatC(prediction, digits = 0, format = "d", big.mark = ","))
  })
  
  session$onSessionEnded(function() {
    h2o.shutdown()
  })
}

shinyApp(ui = ui, server = server)
```

```{r App code}

library(shiny)
ui <- fluidPage(
  titlePanel("House price prediction"),
  sidebarLayout(
    sidebarPanel(
      numericInput("sq_mt_built", "Introduce the square meters of the house you are looking for:", min =15, max = 999 , value = 100),
      numericInput("n_rooms", "Introduce the number of rooms:", value = 3, min = 0, max = 24),
      numericInput("n_bathrooms", "Introduce the number of bathrooms:", value = 2, min = 1, max = 14),
      selectInput("subtitle", "Introduce the district you want to live in:", choices = sort(unique(data$subtitle))),
      selectInput("neighborhood_id", "Introduce the neighborhood you want to live in:", choices = "Select a district first"),
      selectInput("house_type_id", "What kind of house would you like to live in?:", choices = unique(data$house_type_id)),
      conditionalPanel(
        condition = "input.house_type_id != 'HouseType 2: Detached house'",
        selectInput("floor", "Select floor number:", choices = c(sort(unique(data$floor))))),
      
      selectInput("is_floor_under", "Is floor under?:", choices=c("True", "False")),
      selectInput("is_renewal_needed", "Is renewal needed?:", choices=c("True", "False")),
      numericInput("built_year", "Year the house was built in:", value = 2022, min =1800),
      selectInput("has_central_heating", "Has central heating?:", choices=c("True", "False")),
      selectInput("has_individual_heating", "Has individual heating?:", choices=c("True", "False")),
      selectInput("has_ac", "Do you want to have AC?:", choices=c("True", "False")),
      selectInput("has_fitted_wardrobes", "Do you want to have fitted wardrobes?:", choices=c( "True", "False")),
      selectInput("has_lift", "Do you want to have a lift?:", choices=c("True", "False")),
      selectInput("is_exterior", "Do you want it to be exterior?:", choices=c("True", "False")),
      selectInput("has_garden", "Do you want to have a garden?:", choices=c( "True", "False")),
      selectInput("has_pool", "Do you want to have a pool?:", choices=c( "True", "False")),
      selectInput("has_terrace", "Do you want to have a terrace?:", choices=c( "True", "False")),
      selectInput("has_balcony", "Do you want to have a balcony?:", choices=c( "True", "False")),
      selectInput("has_storage_room", "Do you want to have a storage room?:", choices=c( "True", "False")),
      selectInput("is_accessible", "Do you want it to be accessible?:", choices=c( "True", "False")),
      selectInput("has_green_zones", "Do you want to have a green zones?:", choices=c( "True", "False")),
      selectInput("energy_certificate", "What energy certificate would you like it to have?:", choices= sort(unique(data$energy_certificate))),
      selectInput("orientation", "Any preference in orientation:", choices=c("east", "west", "south", "north")),
      
      selectInput("has_parking", "Do you want to have parking?:", choices=c( "True", "False")),
      conditionalPanel(
        condition = "input.has_parking == 'True'",
        selectInput("is_parking_included_in_price", "Parking included in price:", choices = c("True", "False"))),
      ),
      mainPanel(
      h3("The predicted price is:"),
      br(),
      textOutput("predicted_price"))
    )
  )



server = function(input, output, session) {
  
  get_neighborhoods=function(subtitle) {
    unique(data$neighborhood_id[data$subtitle == subtitle])
  }
  
  observe({
    subtitle = input$subtitle
    if (is.null(subtitle) || subtitle == "Select a district") {
      
      updateSelectInput(session, "neighborhood_id", choices = c("Select a district first"))
    } else {
      
      neighborhood_id = get_neighborhoods(subtitle)
      updateSelectInput(session, "neighborhood_id", choices = c( neighborhood_id))
    }
  })
  
  user_data = reactive({
    data.frame(sq_mt_built = input$sq_mt_built,
               n_rooms = input$n_rooms,
               n_bathrooms = input$n_bathrooms,
               subtitle = input$subtitle,
               floor = input$floor,
               is_floor_under = input$is_floor_under,
               neighborhood_id = input$neighborhood_id,
               house_type_id = input$house_type_id,
               is_renewal_needed = input$is_renewal_needed,
               has_central_heating = input$has_central_heating,
               has_individual_heating = input$has_individual_heating,
               built_year = input$built_year,
               has_ac = input$has_ac,
               has_fitted_wardrobes = input$has_fitted_wardrobes,
               has_lift = input$has_lift,
               has_pool = input$has_pool,
               has_storage_room = input$has_storage_room,
               energy_certificate = input$energy_certificate,
               orientation = input$orientation,
               is_exterior = input$is_exterior,
               has_terrace = input$has_terrace,
               is_accessible = input$is_accessible,
               has_parking = input$has_parking,
               has_garden = input$has_garden,
               has_balcony = input$has_balcony,
               has_green_zones = input$has_green_zones,
               is_parking_included_in_price = input$is_parking_included_in_price) })
    

    
  predicted_price = reactive({ predict(elasticnet, user_data())})
  output$predicted_price = renderText({predicted_price()})
}

shinyApp(ui = ui, server = server)


```
